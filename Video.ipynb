{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMkkqvjGP9FY53dBf+EXbfc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VarunB1234/Depression-Detection/blob/main/Video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def processData(data):\n",
        "    X = data.iloc[:, :].values\n",
        "    X = np.delete(X, 0, 1)\n",
        "    X = np.delete(X, 1, 1)\n",
        "    for i in range(len(X)):\n",
        "        if isinstance(X[i][5], str) or isinstance(X[i][7], str):\n",
        "            X[i] = np.zeros((1, X.shape[1]))\n",
        "    return X\n",
        "\n",
        "def getData(filename):\n",
        "    data = pd.read_csv(filename, delimiter=',', engine='python')\n",
        "    X = processData(data)\n",
        "    return X\n",
        "\n",
        "def makeDataPoint(patientNo):\n",
        "    file1 = (patientNo) + \"_CLNF_AUs.txt\"\n",
        "    file2 = (patientNo) + \"_CLNF_features.txt\"\n",
        "    file3 = (patientNo) + \"_CLNF_features3D.txt\"\n",
        "    file4 = (patientNo) + \"_CLNF_gaze.txt\"\n",
        "    file5 = (patientNo) + \"_CLNF_hog.txt\"\n",
        "    file6 = (patientNo) + \"_CLNF_pose.txt\"\n",
        "\n",
        "    X1 = getData(file1)\n",
        "    X2 = getData(file2)\n",
        "    X3 = getData(file3)\n",
        "    X4 = getData(file4)\n",
        "    X6 = getData(file6)\n",
        "\n",
        "    X = np.concatenate((X1, X2, X3, X4, X6), axis=1)\n",
        "    return X\n",
        "\n",
        "def scale_down(X):\n",
        "    X_new = []\n",
        "    size = 2\n",
        "    for i in range(int(X.shape[0]/size)):\n",
        "        cur_row = X[i*size]\n",
        "        for j in range(1, size):\n",
        "            if i + j < X.shape[0]:\n",
        "                cur_row += X[i + j]\n",
        "        cur_row = cur_row / size\n",
        "        X_new.append(cur_row)\n",
        "    return np.array(X_new)\n",
        "\n",
        "def decrease_size(X):\n",
        "    size = 10000\n",
        "    if X.shape[0] < size:\n",
        "        pad = np.zeros((size - X.shape[0], X.shape[1]))\n",
        "        X = np.concatenate((X, pad), axis=0)\n",
        "    else:\n",
        "        X = X[:size, :]\n",
        "    return X\n",
        "\n",
        "def makeDataset(location, folder):\n",
        "    file = np.array(pd.read_csv(location, delimiter=',', encoding='utf-8'))[:, 0:2]\n",
        "    X_temp = []\n",
        "    Y_temp = []\n",
        "    for i in range(len(file)):\n",
        "        patientID = str(int(file[i][0]))\n",
        "        path = '/content/drive/My Drive/MCA Dataset/' + folder + '/' + patientID\n",
        "        XT = makeDataPoint(path)\n",
        "        XT = scale_down(XT)\n",
        "        XT = decrease_size(XT)\n",
        "        X_temp.append(XT)\n",
        "        Y_temp.append(int(file[i][1]))\n",
        "    return X_temp, np.asarray(Y_temp)\n"
      ],
      "metadata": {
        "id": "-NjlqwKUHKvu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = makeDataset('/content/drive/My Drive/MCA Dataset/train_split_Depression_AVEC2017.csv', 'train_data')\n",
        "X_dev, Y_dev = makeDataset('/content/drive/My Drive/MCA Dataset/dev_split_Depression_AVEC2017.csv', 'dev_data')\n"
      ],
      "metadata": {
        "id": "6oDBexC3HPJq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense\n",
        "\n",
        "class CNN_Video:\n",
        "    def __init__(self):\n",
        "        classifier = Sequential()\n",
        "        classifier.add(Input(shape=(10000, 388)))\n",
        "        classifier.add(Conv1D(300, 3, activation='relu'))\n",
        "        classifier.add(MaxPooling1D(pool_size=2))\n",
        "        classifier.add(Conv1D(150, 3, activation='relu'))\n",
        "        classifier.add(MaxPooling1D(pool_size=2))\n",
        "        classifier.add(Conv1D(75, 3, activation='relu'))\n",
        "        classifier.add(MaxPooling1D(pool_size=2))\n",
        "        classifier.add(Conv1D(32, 3, activation='relu'))\n",
        "        classifier.add(MaxPooling1D(pool_size=2))\n",
        "        classifier.add(Flatten())\n",
        "        classifier.add(Dense(128, activation='relu'))\n",
        "        classifier.add(Dense(1, activation='sigmoid'))\n",
        "        classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        self.classifier = classifier\n",
        "\n",
        "    def fitModel(self, X_train, Y_train, epoch=5):\n",
        "        return self.classifier.fit(X_train, Y_train, epochs=epoch)\n",
        "\n",
        "    def predictModel(self, X_test):\n",
        "        return self.classifier.predict(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "UnYWiSWSOSTM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine them\n",
        "X_all = X_train + X_dev\n",
        "Y_all = np.concatenate((Y_train, Y_dev))\n",
        "\n",
        "# Convert to arrays for stratified split\n",
        "X_all = np.array(X_all)\n",
        "Y_all = np.array(Y_all)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# === Manual Stratified Train/Validation Split (90% train / 10% val) ===\n",
        "X_train_split, X_val_split, Y_train_split, Y_val_split = train_test_split(\n",
        "    X_all, Y_all, test_size=0.1, random_state=42, stratify=Y_all\n",
        "\n",
        ")\n",
        "\n",
        "X_train_split = np.array(X_train_split, dtype=np.float32)\n",
        "X_val_split = np.array(X_val_split, dtype=np.float32)\n",
        "Y_train_split = np.array(Y_train_split, dtype=np.float32)\n",
        "Y_val_split = np.array(Y_val_split, dtype=np.float32)\n",
        "\n",
        "# === Build and Train CNN Model ===\n",
        "model = CNN_Video()\n",
        "model.fitModel(X_train_split, Y_train_split, epoch=5)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOtMP-TSHXdt",
        "outputId": "7eb48c9f-9424-4c19-e11e-4caeba7f181f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4s/step - accuracy: 0.6572 - loss: 96443.8516\n",
            "Epoch 2/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6s/step - accuracy: 0.5776 - loss: 48815.3008\n",
            "Epoch 3/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4s/step - accuracy: 0.7105 - loss: 16523.9551\n",
            "Epoch 4/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4s/step - accuracy: 0.5463 - loss: 29445.2344\n",
            "Epoch 5/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4s/step - accuracy: 0.6720 - loss: 13386.4482\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bbdf1f91bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Predict and Evaluate on Validation Set ===\n",
        "Y_val_pred_probs = model.predictModel(X_val_split)\n",
        "Y_val_pred = (Y_val_pred_probs > 0.5).astype(int)\n",
        "from sklearn.metrics import classification_report\n",
        "print(\"Validation Set Evaluation:\")\n",
        "print(classification_report(Y_val_split, Y_val_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7JNKAr7maFr",
        "outputId": "4e74bec1-7283-4296-99d4-c6ebf98a71c4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "Validation Set Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.73      1.00      0.85        11\n",
            "         1.0       0.00      0.00      0.00         4\n",
            "\n",
            "    accuracy                           0.73        15\n",
            "   macro avg       0.37      0.50      0.42        15\n",
            "weighted avg       0.54      0.73      0.62        15\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}